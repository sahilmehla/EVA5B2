{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4 - Session 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python38564bitdeeplearningcondac257645fc1fb45c18f4c5a71b36562b4",
      "display_name": "Python 3.8.5 64-bit ('deeplearning': conda)",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "# Model-1\n",
        "[Link for Model-1](https://github.com/sahilmehla/EVA5B2/blob/main/Session%205/Model_1.ipynb)\n",
        "\n",
        "\n",
        "### Target:\n",
        "\n",
        "1. Get the setup working.\n",
        "2. Set transformers.\n",
        "3. Set Data loader.\n",
        "4. Set Basic working code.\n",
        "5. Set Basic train and test loops.\n",
        "\n",
        "### Results:\n",
        "\n",
        "1. Parameters: 1,834,784\n",
        "2. Best Training Accuracy: 99.54\n",
        "3. Best Test Accuracy: 99.19\n",
        "\n",
        "### Analysis:\n",
        "\n",
        "1. Number of Parameters used are huge for such problem, will be reducing it upto 10000 in next model.\n",
        "2. Model is slightly overfitting."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Model-2\n",
        "[Link for Model-2](https://github.com/sahilmehla/EVA5B2/blob/main/Session%205/Model_2.ipynb)\n",
        "\n",
        "### Target:\n",
        "\n",
        "1. Reduce the number of parameters to less that 10000.\n",
        "\n",
        "### Results:\n",
        "\n",
        "1. Parameters: 9,792\n",
        "2. Best Training Accuracy: 98.92\n",
        "3. Best Test Accuracy: 98.65\n",
        "\n",
        "### Analysis:\n",
        "\n",
        "1. Acurracy slightly reduced with 9,792 parameters, which is ok. \n",
        "2. Slight overfitting is there, but overfitting is good because it can and will be fixed(in Model-4)\n",
        "3. Not able to achieve the desired accuracy i.e. >=99.4, will use batch normalization in next model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Model-3\n",
        "[Link for Model-3](https://github.com/sahilmehla/EVA5B2/blob/main/Session%205/Model_3.ipynb)\n",
        "\n",
        "### Target:\n",
        "\n",
        "1. Add Batch-norm to increase model efficiency.\n",
        "\n",
        "### Results:\n",
        "\n",
        "1. Parameters: 9,960\n",
        "2. Best Training Accuracy: 99.34\n",
        "3. Best Test Accuracy: 99.07\n",
        "\n",
        "### Analysis:\n",
        "\n",
        "1. Overfitting needs to be fixed to improve the accuracy of the model.\n",
        "2. This model can be trained further to achieve the desired accuracy, but not in 15 epochs."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Model-4\n",
        "[Link for Model-4](https://github.com/sahilmehla/EVA5B2/blob/main/Session%205/Model_4.ipynb)\n",
        "\n",
        "### Target:\n",
        "\n",
        "1. Achieve the desired accuracy by fixing the overfitting using regularization and by tunning the lr.\n",
        "\n",
        "### Results:\n",
        "\n",
        "1. Parameters: 9,960\n",
        "2. Best Training Accuracy: 98.53\n",
        "3. Best Test Accuracy: 99.43\n",
        "\n",
        "### Analysis:\n",
        "\n",
        "1. Able to fix the overfitting by using image augmentation(scaling and rotation)\n",
        "2. Dropout is not contributing to increase the test accuracy(infact its decreasing the accuracy as there is no capacity left in the    \n",
        "   model), so dropout_value is set to 0.\n",
        "3. Used StepLR to tune the lr and improve the final accuracy curve.\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}