{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "#################################################\n",
        "## Importing the necessary libraries required \n",
        "## to train \n",
        "#################################################\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "##############################################################################################################################\n",
        "## A typical training procedure for a neural network is as follows:\n",
        "## \n",
        "## 1> Define the neural network that has some learnable parameters (or weights)\n",
        "## 2> Iterate over a dataset of inputs\n",
        "## 3> Process input through the network\n",
        "## 4> Compute the loss (how far is the output from being correct)\n",
        "## 5> Propagate gradients back into the network’s parameters\n",
        "## 6> Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient\n",
        "###############################################################################################################################\n",
        "\n",
        "###################################\n",
        "## Defining the Neural Network\n",
        "###################################\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()                        # Input Size         # Kernel Size         # Output Size       # Receptive Field\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)        #  28x28x1           # 3x3x1               # 28x28x32          # 3x3\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)       #  28x28x32          # 3x3x32              # 28x28x64          # 5x5\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)                    #  28x28x64          # MAXPOOL             # 14x14x64          # 10x10\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)      #  14x14x64          # 3x3x64              # 14x14x128         # 12x12\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)     #  14x14x128         # 3x3x128             # 14x14x256         # 14x14\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)                    #  14x14x256         # MAXPOOL             # 7x7x256           # 28x28\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)                #  7x7x256           # 3x3x256             # 5x5x512           # 30x30\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)               #  5x5x512           # 3x3x512             # 3x3x1024          # 32x32\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)                #  3x3x1024          # 3x3x1024            # 1x1x10            # 34x34\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d0900a-518e-4339-a9c8-f96aa3db8459"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 28, 28]             320\n",
            "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
            "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
            "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
            "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
            "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
            "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
            "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
            "================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.51\n",
            "Params size (MB): 24.34\n",
            "Estimated Total Size (MB): 25.85\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "###############################################\n",
        "## Creating the training and the test dataset.\n",
        "###############################################\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([                                          # Normalizing and transforming the images\n",
        "                        transforms.ToTensor(),                                              # to tensors.\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "################################################################\n",
        "## Defining the model with training and testing parameters.\n",
        "################################################################\n",
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55328aa-fbe2-4b55-c018-3ae02796ae0b"
      },
      "source": [
        "#########################################################\n",
        "### Training the model, with provided hyperparameters ###\n",
        "#########################################################\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 2):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "\n",
            "loss=2.3020811080932617 batch_id=0:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "loss=2.3020811080932617 batch_id=0:   0%|          | 1/469 [00:00<01:08,  6.82it/s]\u001b[A\n",
            "loss=2.3025379180908203 batch_id=1:   0%|          | 1/469 [00:00<01:08,  6.82it/s]\u001b[A\n",
            "loss=2.3024537563323975 batch_id=2:   0%|          | 1/469 [00:00<01:08,  6.82it/s]\u001b[A\n",
            "loss=2.3024537563323975 batch_id=2:   1%|          | 3/469 [00:00<00:56,  8.19it/s]\u001b[A\n",
            "loss=2.301149845123291 batch_id=3:   1%|          | 3/469 [00:00<00:56,  8.19it/s] \u001b[A\n",
            "loss=2.3020060062408447 batch_id=4:   1%|          | 3/469 [00:00<00:56,  8.19it/s]\u001b[A\n",
            "loss=2.3020060062408447 batch_id=4:   1%|          | 5/469 [00:00<00:47,  9.72it/s]\u001b[A\n",
            "loss=2.302729368209839 batch_id=5:   1%|          | 5/469 [00:00<00:47,  9.72it/s] \u001b[A\n",
            "loss=2.303950309753418 batch_id=6:   1%|          | 5/469 [00:00<00:47,  9.72it/s]\u001b[A\n",
            "loss=2.300626754760742 batch_id=7:   1%|          | 5/469 [00:00<00:47,  9.72it/s]\u001b[A\n",
            "loss=2.300626754760742 batch_id=7:   2%|▏         | 8/469 [00:00<00:38, 11.98it/s]\u001b[A\n",
            "loss=2.300551652908325 batch_id=8:   2%|▏         | 8/469 [00:00<00:38, 11.98it/s]\u001b[A\n",
            "loss=2.299664258956909 batch_id=9:   2%|▏         | 8/469 [00:00<00:38, 11.98it/s]\u001b[A\n",
            "loss=2.3010644912719727 batch_id=10:   2%|▏         | 8/469 [00:00<00:38, 11.98it/s]\u001b[A\n",
            "loss=2.3010644912719727 batch_id=10:   2%|▏         | 11/469 [00:00<00:33, 13.67it/s]\u001b[A\n",
            "loss=2.302532196044922 batch_id=11:   2%|▏         | 11/469 [00:00<00:33, 13.67it/s] \u001b[A\n",
            "loss=2.302717447280884 batch_id=12:   2%|▏         | 11/469 [00:00<00:33, 13.67it/s]\u001b[A\n",
            "loss=2.30137038230896 batch_id=13:   2%|▏         | 11/469 [00:00<00:33, 13.67it/s] \u001b[A\n",
            "loss=2.30137038230896 batch_id=13:   3%|▎         | 14/469 [00:00<00:29, 15.57it/s]\u001b[A\n",
            "loss=2.3018901348114014 batch_id=14:   3%|▎         | 14/469 [00:00<00:29, 15.57it/s]\u001b[A\n",
            "loss=2.3003222942352295 batch_id=15:   3%|▎         | 14/469 [00:00<00:29, 15.57it/s]\u001b[A\n",
            "loss=2.2994165420532227 batch_id=16:   3%|▎         | 14/469 [00:00<00:29, 15.57it/s]\u001b[A\n",
            "loss=2.2994165420532227 batch_id=16:   4%|▎         | 17/469 [00:00<00:26, 16.95it/s]\u001b[A\n",
            "loss=2.294935703277588 batch_id=17:   4%|▎         | 17/469 [00:00<00:26, 16.95it/s] \u001b[A\n",
            "loss=2.298707962036133 batch_id=18:   4%|▎         | 17/469 [00:01<00:26, 16.95it/s]\u001b[A\n",
            "loss=2.300943613052368 batch_id=19:   4%|▎         | 17/469 [00:01<00:26, 16.95it/s]\u001b[A\n",
            "loss=2.300943613052368 batch_id=19:   4%|▍         | 20/469 [00:01<00:24, 18.09it/s]\u001b[A\n",
            "loss=2.296154022216797 batch_id=20:   4%|▍         | 20/469 [00:01<00:24, 18.09it/s]\u001b[A\n",
            "loss=2.298391819000244 batch_id=21:   4%|▍         | 20/469 [00:01<00:24, 18.09it/s]\u001b[A\n",
            "loss=2.29833984375 batch_id=22:   4%|▍         | 20/469 [00:01<00:24, 18.09it/s]    \u001b[A\n",
            "loss=2.29833984375 batch_id=22:   5%|▍         | 23/469 [00:01<00:23, 19.36it/s]\u001b[A\n",
            "loss=2.293813943862915 batch_id=23:   5%|▍         | 23/469 [00:01<00:23, 19.36it/s]\u001b[A\n",
            "loss=2.2988104820251465 batch_id=24:   5%|▍         | 23/469 [00:01<00:23, 19.36it/s]\u001b[A\n",
            "loss=2.2984986305236816 batch_id=25:   5%|▍         | 23/469 [00:01<00:23, 19.36it/s]\u001b[A\n",
            "loss=2.2984986305236816 batch_id=25:   6%|▌         | 26/469 [00:01<00:21, 20.33it/s]\u001b[A\n",
            "loss=2.3022334575653076 batch_id=26:   6%|▌         | 26/469 [00:01<00:21, 20.33it/s]\u001b[A\n",
            "loss=2.299490213394165 batch_id=27:   6%|▌         | 26/469 [00:01<00:21, 20.33it/s] \u001b[A\n",
            "loss=2.2971131801605225 batch_id=28:   6%|▌         | 26/469 [00:01<00:21, 20.33it/s]\u001b[A\n",
            "loss=2.2971131801605225 batch_id=28:   6%|▌         | 29/469 [00:01<00:20, 21.01it/s]\u001b[A\n",
            "loss=2.2963407039642334 batch_id=29:   6%|▌         | 29/469 [00:01<00:20, 21.01it/s]\u001b[A\n",
            "loss=2.291435480117798 batch_id=30:   6%|▌         | 29/469 [00:01<00:20, 21.01it/s] \u001b[A\n",
            "loss=2.294631004333496 batch_id=31:   6%|▌         | 29/469 [00:01<00:20, 21.01it/s]\u001b[A\n",
            "loss=2.294631004333496 batch_id=31:   7%|▋         | 32/469 [00:01<00:20, 21.61it/s]\u001b[A\n",
            "loss=2.288696527481079 batch_id=32:   7%|▋         | 32/469 [00:01<00:20, 21.61it/s]\u001b[A\n",
            "loss=2.297973871231079 batch_id=33:   7%|▋         | 32/469 [00:01<00:20, 21.61it/s]\u001b[A\n",
            "loss=2.2965290546417236 batch_id=34:   7%|▋         | 32/469 [00:01<00:20, 21.61it/s]\u001b[A\n",
            "loss=2.2965290546417236 batch_id=34:   7%|▋         | 35/469 [00:01<00:19, 22.07it/s]\u001b[A\n",
            "loss=2.291710615158081 batch_id=35:   7%|▋         | 35/469 [00:01<00:19, 22.07it/s] \u001b[A\n",
            "loss=2.2890191078186035 batch_id=36:   7%|▋         | 35/469 [00:01<00:19, 22.07it/s]\u001b[A\n",
            "loss=2.299428939819336 batch_id=37:   7%|▋         | 35/469 [00:01<00:19, 22.07it/s] \u001b[A\n",
            "loss=2.299428939819336 batch_id=37:   8%|▊         | 38/469 [00:01<00:18, 22.82it/s]\u001b[A\n",
            "loss=2.2847540378570557 batch_id=38:   8%|▊         | 38/469 [00:01<00:18, 22.82it/s]\u001b[A\n",
            "loss=2.290522813796997 batch_id=39:   8%|▊         | 38/469 [00:01<00:18, 22.82it/s] \u001b[A\n",
            "loss=2.2784838676452637 batch_id=40:   8%|▊         | 38/469 [00:01<00:18, 22.82it/s]\u001b[A\n",
            "loss=2.2784838676452637 batch_id=40:   9%|▊         | 41/469 [00:01<00:18, 23.45it/s]\u001b[A\n",
            "loss=2.2906832695007324 batch_id=41:   9%|▊         | 41/469 [00:01<00:18, 23.45it/s]\u001b[A\n",
            "loss=2.291642427444458 batch_id=42:   9%|▊         | 41/469 [00:02<00:18, 23.45it/s] \u001b[A\n",
            "loss=2.289677619934082 batch_id=43:   9%|▊         | 41/469 [00:02<00:18, 23.45it/s]\u001b[A\n",
            "loss=2.289677619934082 batch_id=43:   9%|▉         | 44/469 [00:02<00:17, 24.26it/s]\u001b[A\n",
            "loss=2.2921624183654785 batch_id=44:   9%|▉         | 44/469 [00:02<00:17, 24.26it/s]\u001b[A\n",
            "loss=2.2762391567230225 batch_id=45:   9%|▉         | 44/469 [00:02<00:17, 24.26it/s]\u001b[A\n",
            "loss=2.2712690830230713 batch_id=46:   9%|▉         | 44/469 [00:02<00:17, 24.26it/s]\u001b[A\n",
            "loss=2.2712690830230713 batch_id=46:  10%|█         | 47/469 [00:02<00:17, 23.75it/s]\u001b[A\n",
            "loss=2.2838306427001953 batch_id=47:  10%|█         | 47/469 [00:02<00:17, 23.75it/s]\u001b[A\n",
            "loss=2.2820053100585938 batch_id=48:  10%|█         | 47/469 [00:02<00:17, 23.75it/s]\u001b[A\n",
            "loss=2.2715444564819336 batch_id=49:  10%|█         | 47/469 [00:02<00:17, 23.75it/s]\u001b[A\n",
            "loss=2.2715444564819336 batch_id=49:  11%|█         | 50/469 [00:02<00:17, 23.80it/s]\u001b[A\n",
            "loss=2.2775251865386963 batch_id=50:  11%|█         | 50/469 [00:02<00:17, 23.80it/s]\u001b[A\n",
            "loss=2.2833666801452637 batch_id=51:  11%|█         | 50/469 [00:02<00:17, 23.80it/s]\u001b[A\n",
            "loss=2.281484603881836 batch_id=52:  11%|█         | 50/469 [00:02<00:17, 23.80it/s] \u001b[A\n",
            "loss=2.281484603881836 batch_id=52:  11%|█▏        | 53/469 [00:02<00:17, 23.90it/s]\u001b[A\n",
            "loss=2.264921188354492 batch_id=53:  11%|█▏        | 53/469 [00:02<00:17, 23.90it/s]\u001b[A\n",
            "loss=2.255868911743164 batch_id=54:  11%|█▏        | 53/469 [00:02<00:17, 23.90it/s]\u001b[A\n",
            "loss=2.2613935470581055 batch_id=55:  11%|█▏        | 53/469 [00:02<00:17, 23.90it/s]\u001b[A\n",
            "loss=2.2613935470581055 batch_id=55:  12%|█▏        | 56/469 [00:02<00:17, 23.97it/s]\u001b[A\n",
            "loss=2.229006767272949 batch_id=56:  12%|█▏        | 56/469 [00:02<00:17, 23.97it/s] \u001b[A\n",
            "loss=2.2824296951293945 batch_id=57:  12%|█▏        | 56/469 [00:02<00:17, 23.97it/s]\u001b[A\n",
            "loss=2.2484734058380127 batch_id=58:  12%|█▏        | 56/469 [00:02<00:17, 23.97it/s]\u001b[A\n",
            "loss=2.2484734058380127 batch_id=58:  13%|█▎        | 59/469 [00:02<00:17, 24.04it/s]\u001b[A\n",
            "loss=2.244359016418457 batch_id=59:  13%|█▎        | 59/469 [00:02<00:17, 24.04it/s] \u001b[A\n",
            "loss=2.212080478668213 batch_id=60:  13%|█▎        | 59/469 [00:02<00:17, 24.04it/s]\u001b[A\n",
            "loss=2.263295888900757 batch_id=61:  13%|█▎        | 59/469 [00:02<00:17, 24.04it/s]\u001b[A\n",
            "loss=2.263295888900757 batch_id=61:  13%|█▎        | 62/469 [00:02<00:16, 24.40it/s]\u001b[A\n",
            "loss=2.2588140964508057 batch_id=62:  13%|█▎        | 62/469 [00:02<00:16, 24.40it/s]\u001b[A\n",
            "loss=2.1958272457122803 batch_id=63:  13%|█▎        | 62/469 [00:02<00:16, 24.40it/s]\u001b[A\n",
            "loss=2.1840639114379883 batch_id=64:  13%|█▎        | 62/469 [00:02<00:16, 24.40it/s]\u001b[A\n",
            "loss=2.1840639114379883 batch_id=64:  14%|█▍        | 65/469 [00:02<00:16, 24.38it/s]\u001b[A\n",
            "loss=2.219097375869751 batch_id=65:  14%|█▍        | 65/469 [00:02<00:16, 24.38it/s] \u001b[A\n",
            "loss=2.146660327911377 batch_id=66:  14%|█▍        | 65/469 [00:03<00:16, 24.38it/s]\u001b[A\n",
            "loss=2.145637035369873 batch_id=67:  14%|█▍        | 65/469 [00:03<00:16, 24.38it/s]\u001b[A\n",
            "loss=2.145637035369873 batch_id=67:  14%|█▍        | 68/469 [00:03<00:16, 24.53it/s]\u001b[A\n",
            "loss=2.121518135070801 batch_id=68:  14%|█▍        | 68/469 [00:03<00:16, 24.53it/s]\u001b[A\n",
            "loss=2.1505789756774902 batch_id=69:  14%|█▍        | 68/469 [00:03<00:16, 24.53it/s]\u001b[A\n",
            "loss=2.1665289402008057 batch_id=70:  14%|█▍        | 68/469 [00:03<00:16, 24.53it/s]\u001b[A\n",
            "loss=2.1665289402008057 batch_id=70:  15%|█▌        | 71/469 [00:03<00:16, 24.84it/s]\u001b[A\n",
            "loss=2.0851640701293945 batch_id=71:  15%|█▌        | 71/469 [00:03<00:16, 24.84it/s]\u001b[A\n",
            "loss=2.0862343311309814 batch_id=72:  15%|█▌        | 71/469 [00:03<00:16, 24.84it/s]\u001b[A\n",
            "loss=1.9608819484710693 batch_id=73:  15%|█▌        | 71/469 [00:03<00:16, 24.84it/s]\u001b[A\n",
            "loss=1.9608819484710693 batch_id=73:  16%|█▌        | 74/469 [00:03<00:16, 24.31it/s]\u001b[A\n",
            "loss=2.1163361072540283 batch_id=74:  16%|█▌        | 74/469 [00:03<00:16, 24.31it/s]\u001b[A\n",
            "loss=2.088914632797241 batch_id=75:  16%|█▌        | 74/469 [00:03<00:16, 24.31it/s] \u001b[A\n",
            "loss=1.9395568370819092 batch_id=76:  16%|█▌        | 74/469 [00:03<00:16, 24.31it/s]\u001b[A\n",
            "loss=1.9395568370819092 batch_id=76:  16%|█▋        | 77/469 [00:03<00:16, 24.35it/s]\u001b[A\n",
            "loss=2.052551507949829 batch_id=77:  16%|█▋        | 77/469 [00:03<00:16, 24.35it/s] \u001b[A\n",
            "loss=1.9901328086853027 batch_id=78:  16%|█▋        | 77/469 [00:03<00:16, 24.35it/s]\u001b[A\n",
            "loss=2.0183584690093994 batch_id=79:  16%|█▋        | 77/469 [00:03<00:16, 24.35it/s]\u001b[A\n",
            "loss=2.0183584690093994 batch_id=79:  17%|█▋        | 80/469 [00:03<00:15, 24.74it/s]\u001b[A\n",
            "loss=2.0713002681732178 batch_id=80:  17%|█▋        | 80/469 [00:03<00:15, 24.74it/s]\u001b[A\n",
            "loss=2.057771682739258 batch_id=81:  17%|█▋        | 80/469 [00:03<00:15, 24.74it/s] \u001b[A\n",
            "loss=2.0894594192504883 batch_id=82:  17%|█▋        | 80/469 [00:03<00:15, 24.74it/s]\u001b[A\n",
            "loss=2.0894594192504883 batch_id=82:  18%|█▊        | 83/469 [00:03<00:15, 24.82it/s]\u001b[A\n",
            "loss=1.9343030452728271 batch_id=83:  18%|█▊        | 83/469 [00:03<00:15, 24.82it/s]\u001b[A\n",
            "loss=1.9854631423950195 batch_id=84:  18%|█▊        | 83/469 [00:03<00:15, 24.82it/s]\u001b[A\n",
            "loss=1.933921456336975 batch_id=85:  18%|█▊        | 83/469 [00:03<00:15, 24.82it/s] \u001b[A\n",
            "loss=1.933921456336975 batch_id=85:  18%|█▊        | 86/469 [00:03<00:15, 24.83it/s]\u001b[A\n",
            "loss=2.012967348098755 batch_id=86:  18%|█▊        | 86/469 [00:03<00:15, 24.83it/s]\u001b[A\n",
            "loss=1.983388900756836 batch_id=87:  18%|█▊        | 86/469 [00:03<00:15, 24.83it/s]\u001b[A\n",
            "loss=2.0205740928649902 batch_id=88:  18%|█▊        | 86/469 [00:03<00:15, 24.83it/s]\u001b[A\n",
            "loss=2.0205740928649902 batch_id=88:  19%|█▉        | 89/469 [00:03<00:15, 23.97it/s]\u001b[A\n",
            "loss=2.081881523132324 batch_id=89:  19%|█▉        | 89/469 [00:03<00:15, 23.97it/s] \u001b[A\n",
            "loss=1.9275829792022705 batch_id=90:  19%|█▉        | 89/469 [00:04<00:15, 23.97it/s]\u001b[A\n",
            "loss=1.970145583152771 batch_id=91:  19%|█▉        | 89/469 [00:04<00:15, 23.97it/s] \u001b[A\n",
            "loss=1.970145583152771 batch_id=91:  20%|█▉        | 92/469 [00:04<00:16, 22.69it/s]\u001b[A\n",
            "loss=1.801379680633545 batch_id=92:  20%|█▉        | 92/469 [00:04<00:16, 22.69it/s]\u001b[A\n",
            "loss=2.0121772289276123 batch_id=93:  20%|█▉        | 92/469 [00:04<00:16, 22.69it/s]\u001b[A\n",
            "loss=2.096203088760376 batch_id=94:  20%|█▉        | 92/469 [00:04<00:16, 22.69it/s] \u001b[A\n",
            "loss=2.096203088760376 batch_id=94:  20%|██        | 95/469 [00:04<00:16, 22.08it/s]\u001b[A\n",
            "loss=1.8766225576400757 batch_id=95:  20%|██        | 95/469 [00:04<00:16, 22.08it/s]\u001b[A\n",
            "loss=2.0568594932556152 batch_id=96:  20%|██        | 95/469 [00:04<00:16, 22.08it/s]\u001b[A\n",
            "loss=2.1090714931488037 batch_id=97:  20%|██        | 95/469 [00:04<00:16, 22.08it/s]\u001b[A\n",
            "loss=2.1090714931488037 batch_id=97:  21%|██        | 98/469 [00:04<00:16, 22.09it/s]\u001b[A\n",
            "loss=2.0015463829040527 batch_id=98:  21%|██        | 98/469 [00:04<00:16, 22.09it/s]\u001b[A\n",
            "loss=2.0039618015289307 batch_id=99:  21%|██        | 98/469 [00:04<00:16, 22.09it/s]\u001b[A\n",
            "loss=2.010056257247925 batch_id=100:  21%|██        | 98/469 [00:04<00:16, 22.09it/s]\u001b[A\n",
            "loss=2.010056257247925 batch_id=100:  22%|██▏       | 101/469 [00:04<00:16, 22.63it/s]\u001b[A\n",
            "loss=2.0157392024993896 batch_id=101:  22%|██▏       | 101/469 [00:04<00:16, 22.63it/s]\u001b[A\n",
            "loss=1.9529666900634766 batch_id=102:  22%|██▏       | 101/469 [00:04<00:16, 22.63it/s]\u001b[A\n",
            "loss=1.8927146196365356 batch_id=103:  22%|██▏       | 101/469 [00:04<00:16, 22.63it/s]\u001b[A\n",
            "loss=1.8927146196365356 batch_id=103:  22%|██▏       | 104/469 [00:04<00:16, 21.52it/s]\u001b[A\n",
            "loss=1.8053287267684937 batch_id=104:  22%|██▏       | 104/469 [00:04<00:16, 21.52it/s]\u001b[A\n",
            "loss=1.9876917600631714 batch_id=105:  22%|██▏       | 104/469 [00:04<00:16, 21.52it/s]\u001b[A\n",
            "loss=2.1965527534484863 batch_id=106:  22%|██▏       | 104/469 [00:04<00:16, 21.52it/s]\u001b[A\n",
            "loss=2.1965527534484863 batch_id=106:  23%|██▎       | 107/469 [00:04<00:16, 21.74it/s]\u001b[A\n",
            "loss=1.9673949480056763 batch_id=107:  23%|██▎       | 107/469 [00:04<00:16, 21.74it/s]\u001b[A\n",
            "loss=1.8264027833938599 batch_id=108:  23%|██▎       | 107/469 [00:04<00:16, 21.74it/s]\u001b[A\n",
            "loss=1.9399439096450806 batch_id=109:  23%|██▎       | 107/469 [00:04<00:16, 21.74it/s]\u001b[A\n",
            "loss=1.9399439096450806 batch_id=109:  23%|██▎       | 110/469 [00:04<00:16, 22.00it/s]\u001b[A\n",
            "loss=1.8750544786453247 batch_id=110:  23%|██▎       | 110/469 [00:04<00:16, 22.00it/s]\u001b[A\n",
            "loss=1.9359896183013916 batch_id=111:  23%|██▎       | 110/469 [00:04<00:16, 22.00it/s]\u001b[A\n",
            "loss=2.000558376312256 batch_id=112:  23%|██▎       | 110/469 [00:05<00:16, 22.00it/s] \u001b[A\n",
            "loss=2.000558376312256 batch_id=112:  24%|██▍       | 113/469 [00:05<00:15, 23.14it/s]\u001b[A\n",
            "loss=1.9506726264953613 batch_id=113:  24%|██▍       | 113/469 [00:05<00:15, 23.14it/s]\u001b[A\n",
            "loss=1.975273609161377 batch_id=114:  24%|██▍       | 113/469 [00:05<00:15, 23.14it/s] \u001b[A\n",
            "loss=1.9542648792266846 batch_id=115:  24%|██▍       | 113/469 [00:05<00:15, 23.14it/s]\u001b[A\n",
            "loss=1.9542648792266846 batch_id=115:  25%|██▍       | 116/469 [00:05<00:14, 23.88it/s]\u001b[A\n",
            "loss=1.9502100944519043 batch_id=116:  25%|██▍       | 116/469 [00:05<00:14, 23.88it/s]\u001b[A\n",
            "loss=1.9953306913375854 batch_id=117:  25%|██▍       | 116/469 [00:05<00:14, 23.88it/s]\u001b[A\n",
            "loss=1.9068996906280518 batch_id=118:  25%|██▍       | 116/469 [00:05<00:14, 23.88it/s]\u001b[A\n",
            "loss=1.9068996906280518 batch_id=118:  25%|██▌       | 119/469 [00:05<00:14, 24.12it/s]\u001b[A\n",
            "loss=1.9221550226211548 batch_id=119:  25%|██▌       | 119/469 [00:05<00:14, 24.12it/s]\u001b[A\n",
            "loss=1.979272723197937 batch_id=120:  25%|██▌       | 119/469 [00:05<00:14, 24.12it/s] \u001b[A\n",
            "loss=1.944522738456726 batch_id=121:  25%|██▌       | 119/469 [00:05<00:14, 24.12it/s]\u001b[A\n",
            "loss=1.944522738456726 batch_id=121:  26%|██▌       | 122/469 [00:05<00:14, 23.42it/s]\u001b[A\n",
            "loss=1.9707823991775513 batch_id=122:  26%|██▌       | 122/469 [00:05<00:14, 23.42it/s]\u001b[A\n",
            "loss=1.9723345041275024 batch_id=123:  26%|██▌       | 122/469 [00:05<00:14, 23.42it/s]\u001b[A\n",
            "loss=1.995255708694458 batch_id=124:  26%|██▌       | 122/469 [00:05<00:14, 23.42it/s] \u001b[A\n",
            "loss=1.995255708694458 batch_id=124:  27%|██▋       | 125/469 [00:05<00:14, 24.23it/s]\u001b[A\n",
            "loss=2.0735442638397217 batch_id=125:  27%|██▋       | 125/469 [00:05<00:14, 24.23it/s]\u001b[A\n",
            "loss=1.9655675888061523 batch_id=126:  27%|██▋       | 125/469 [00:05<00:14, 24.23it/s]\u001b[A\n",
            "loss=1.9111063480377197 batch_id=127:  27%|██▋       | 125/469 [00:05<00:14, 24.23it/s]\u001b[A\n",
            "loss=1.9111063480377197 batch_id=127:  27%|██▋       | 128/469 [00:05<00:14, 23.66it/s]\u001b[A\n",
            "loss=1.936777949333191 batch_id=128:  27%|██▋       | 128/469 [00:05<00:14, 23.66it/s] \u001b[A\n",
            "loss=1.941746473312378 batch_id=129:  27%|██▋       | 128/469 [00:05<00:14, 23.66it/s]\u001b[A\n",
            "loss=1.860548496246338 batch_id=130:  27%|██▋       | 128/469 [00:05<00:14, 23.66it/s]\u001b[A\n",
            "loss=1.860548496246338 batch_id=130:  28%|██▊       | 131/469 [00:05<00:14, 23.89it/s]\u001b[A\n",
            "loss=1.895391821861267 batch_id=131:  28%|██▊       | 131/469 [00:05<00:14, 23.89it/s]\u001b[A\n",
            "loss=1.9430341720581055 batch_id=132:  28%|██▊       | 131/469 [00:05<00:14, 23.89it/s]\u001b[A\n",
            "loss=1.9604666233062744 batch_id=133:  28%|██▊       | 131/469 [00:05<00:14, 23.89it/s]\u001b[A\n",
            "loss=1.9604666233062744 batch_id=133:  29%|██▊       | 134/469 [00:05<00:13, 24.27it/s]\u001b[A\n",
            "loss=1.9354746341705322 batch_id=134:  29%|██▊       | 134/469 [00:05<00:13, 24.27it/s]\u001b[A\n",
            "loss=1.8282227516174316 batch_id=135:  29%|██▊       | 134/469 [00:05<00:13, 24.27it/s]\u001b[A\n",
            "loss=1.7395329475402832 batch_id=136:  29%|██▊       | 134/469 [00:06<00:13, 24.27it/s]\u001b[A\n",
            "loss=1.7395329475402832 batch_id=136:  29%|██▉       | 137/469 [00:06<00:14, 23.18it/s]\u001b[A\n",
            "loss=1.9877514839172363 batch_id=137:  29%|██▉       | 137/469 [00:06<00:14, 23.18it/s]\u001b[A\n",
            "loss=1.7970056533813477 batch_id=138:  29%|██▉       | 137/469 [00:06<00:14, 23.18it/s]\u001b[A\n",
            "loss=1.9334403276443481 batch_id=139:  29%|██▉       | 137/469 [00:06<00:14, 23.18it/s]\u001b[A\n",
            "loss=1.9334403276443481 batch_id=139:  30%|██▉       | 140/469 [00:06<00:14, 22.24it/s]\u001b[A\n",
            "loss=1.9200700521469116 batch_id=140:  30%|██▉       | 140/469 [00:06<00:14, 22.24it/s]\u001b[A\n",
            "loss=1.8854974508285522 batch_id=141:  30%|██▉       | 140/469 [00:06<00:14, 22.24it/s]\u001b[A\n",
            "loss=1.9780246019363403 batch_id=142:  30%|██▉       | 140/469 [00:06<00:14, 22.24it/s]\u001b[A\n",
            "loss=1.9780246019363403 batch_id=142:  30%|███       | 143/469 [00:06<00:14, 22.09it/s]\u001b[A\n",
            "loss=1.8951432704925537 batch_id=143:  30%|███       | 143/469 [00:06<00:14, 22.09it/s]\u001b[A\n",
            "loss=1.8504970073699951 batch_id=144:  30%|███       | 143/469 [00:06<00:14, 22.09it/s]\u001b[A\n",
            "loss=1.8014477491378784 batch_id=145:  30%|███       | 143/469 [00:06<00:14, 22.09it/s]\u001b[A\n",
            "loss=1.8014477491378784 batch_id=145:  31%|███       | 146/469 [00:06<00:14, 21.78it/s]\u001b[A\n",
            "loss=1.8733546733856201 batch_id=146:  31%|███       | 146/469 [00:06<00:14, 21.78it/s]\u001b[A\n",
            "loss=1.837831974029541 batch_id=147:  31%|███       | 146/469 [00:06<00:14, 21.78it/s] \u001b[A\n",
            "loss=1.8968943357467651 batch_id=148:  31%|███       | 146/469 [00:06<00:14, 21.78it/s]\u001b[A\n",
            "loss=1.8968943357467651 batch_id=148:  32%|███▏      | 149/469 [00:06<00:14, 21.60it/s]\u001b[A\n",
            "loss=1.9005966186523438 batch_id=149:  32%|███▏      | 149/469 [00:06<00:14, 21.60it/s]\u001b[A\n",
            "loss=1.9264386892318726 batch_id=150:  32%|███▏      | 149/469 [00:06<00:14, 21.60it/s]\u001b[A\n",
            "loss=2.1164779663085938 batch_id=151:  32%|███▏      | 149/469 [00:06<00:14, 21.60it/s]\u001b[A\n",
            "loss=2.1164779663085938 batch_id=151:  32%|███▏      | 152/469 [00:06<00:14, 21.45it/s]\u001b[A\n",
            "loss=1.9898947477340698 batch_id=152:  32%|███▏      | 152/469 [00:06<00:14, 21.45it/s]\u001b[A\n",
            "loss=1.9076285362243652 batch_id=153:  32%|███▏      | 152/469 [00:06<00:14, 21.45it/s]\u001b[A\n",
            "loss=1.898710012435913 batch_id=154:  32%|███▏      | 152/469 [00:06<00:14, 21.45it/s] \u001b[A\n",
            "loss=1.898710012435913 batch_id=154:  33%|███▎      | 155/469 [00:06<00:14, 22.29it/s]\u001b[A\n",
            "loss=1.9826433658599854 batch_id=155:  33%|███▎      | 155/469 [00:06<00:14, 22.29it/s]\u001b[A\n",
            "loss=1.8325732946395874 batch_id=156:  33%|███▎      | 155/469 [00:06<00:14, 22.29it/s]\u001b[A\n",
            "loss=1.9520187377929688 batch_id=157:  33%|███▎      | 155/469 [00:06<00:14, 22.29it/s]\u001b[A\n",
            "loss=1.9520187377929688 batch_id=157:  34%|███▎      | 158/469 [00:06<00:14, 22.01it/s]\u001b[A\n",
            "loss=2.0243756771087646 batch_id=158:  34%|███▎      | 158/469 [00:07<00:14, 22.01it/s]\u001b[A\n",
            "loss=1.9830628633499146 batch_id=159:  34%|███▎      | 158/469 [00:07<00:14, 22.01it/s]\u001b[A\n",
            "loss=1.8753650188446045 batch_id=160:  34%|███▎      | 158/469 [00:07<00:14, 22.01it/s]\u001b[A\n",
            "loss=1.8753650188446045 batch_id=160:  34%|███▍      | 161/469 [00:07<00:13, 22.91it/s]\u001b[A\n",
            "loss=1.9655927419662476 batch_id=161:  34%|███▍      | 161/469 [00:07<00:13, 22.91it/s]\u001b[A\n",
            "loss=1.880263328552246 batch_id=162:  34%|███▍      | 161/469 [00:07<00:13, 22.91it/s] \u001b[A\n",
            "loss=1.918290138244629 batch_id=163:  34%|███▍      | 161/469 [00:07<00:13, 22.91it/s]\u001b[A\n",
            "loss=1.918290138244629 batch_id=163:  35%|███▍      | 164/469 [00:07<00:13, 23.24it/s]\u001b[A\n",
            "loss=1.936061143875122 batch_id=164:  35%|███▍      | 164/469 [00:07<00:13, 23.24it/s]\u001b[A\n",
            "loss=1.8057290315628052 batch_id=165:  35%|███▍      | 164/469 [00:07<00:13, 23.24it/s]\u001b[A\n",
            "loss=1.8703538179397583 batch_id=166:  35%|███▍      | 164/469 [00:07<00:13, 23.24it/s]\u001b[A\n",
            "loss=1.8703538179397583 batch_id=166:  36%|███▌      | 167/469 [00:07<00:12, 23.44it/s]\u001b[A\n",
            "loss=1.9023679494857788 batch_id=167:  36%|███▌      | 167/469 [00:07<00:12, 23.44it/s]\u001b[A\n",
            "loss=1.8482128381729126 batch_id=168:  36%|███▌      | 167/469 [00:07<00:12, 23.44it/s]\u001b[A\n",
            "loss=1.8664311170578003 batch_id=169:  36%|███▌      | 167/469 [00:07<00:12, 23.44it/s]\u001b[A\n",
            "loss=1.8664311170578003 batch_id=169:  36%|███▌      | 170/469 [00:07<00:12, 24.46it/s]\u001b[A\n",
            "loss=1.8696106672286987 batch_id=170:  36%|███▌      | 170/469 [00:07<00:12, 24.46it/s]\u001b[A\n",
            "loss=1.911115288734436 batch_id=171:  36%|███▌      | 170/469 [00:07<00:12, 24.46it/s] \u001b[A\n",
            "loss=2.0152816772460938 batch_id=172:  36%|███▌      | 170/469 [00:07<00:12, 24.46it/s]\u001b[A\n",
            "loss=2.0152816772460938 batch_id=172:  37%|███▋      | 173/469 [00:07<00:12, 24.43it/s]\u001b[A\n",
            "loss=1.9689044952392578 batch_id=173:  37%|███▋      | 173/469 [00:07<00:12, 24.43it/s]\u001b[A\n",
            "loss=1.938277244567871 batch_id=174:  37%|███▋      | 173/469 [00:07<00:12, 24.43it/s] \u001b[A\n",
            "loss=1.892747402191162 batch_id=175:  37%|███▋      | 173/469 [00:07<00:12, 24.43it/s]\u001b[A\n",
            "loss=1.892747402191162 batch_id=175:  38%|███▊      | 176/469 [00:07<00:12, 24.24it/s]\u001b[A\n",
            "loss=1.981736183166504 batch_id=176:  38%|███▊      | 176/469 [00:07<00:12, 24.24it/s]\u001b[A\n",
            "loss=1.9608287811279297 batch_id=177:  38%|███▊      | 176/469 [00:07<00:12, 24.24it/s]\u001b[A\n",
            "loss=2.0149779319763184 batch_id=178:  38%|███▊      | 176/469 [00:07<00:12, 24.24it/s]\u001b[A\n",
            "loss=2.0149779319763184 batch_id=178:  38%|███▊      | 179/469 [00:07<00:12, 23.51it/s]\u001b[A\n",
            "loss=1.8455392122268677 batch_id=179:  38%|███▊      | 179/469 [00:07<00:12, 23.51it/s]\u001b[A\n",
            "loss=1.9857639074325562 batch_id=180:  38%|███▊      | 179/469 [00:07<00:12, 23.51it/s]\u001b[A\n",
            "loss=1.9028562307357788 batch_id=181:  38%|███▊      | 179/469 [00:07<00:12, 23.51it/s]\u001b[A\n",
            "loss=1.9028562307357788 batch_id=181:  39%|███▉      | 182/469 [00:07<00:12, 23.54it/s]\u001b[A\n",
            "loss=1.8563438653945923 batch_id=182:  39%|███▉      | 182/469 [00:08<00:12, 23.54it/s]\u001b[A\n",
            "loss=1.8755868673324585 batch_id=183:  39%|███▉      | 182/469 [00:08<00:12, 23.54it/s]\u001b[A\n",
            "loss=1.9883614778518677 batch_id=184:  39%|███▉      | 182/469 [00:08<00:12, 23.54it/s]\u001b[A\n",
            "loss=1.9883614778518677 batch_id=184:  39%|███▉      | 185/469 [00:08<00:12, 22.59it/s]\u001b[A\n",
            "loss=1.9825677871704102 batch_id=185:  39%|███▉      | 185/469 [00:08<00:12, 22.59it/s]\u001b[A\n",
            "loss=1.9173946380615234 batch_id=186:  39%|███▉      | 185/469 [00:08<00:12, 22.59it/s]\u001b[A\n",
            "loss=1.927031397819519 batch_id=187:  39%|███▉      | 185/469 [00:08<00:12, 22.59it/s] \u001b[A\n",
            "loss=1.927031397819519 batch_id=187:  40%|████      | 188/469 [00:08<00:13, 20.97it/s]\u001b[A\n",
            "loss=2.0096540451049805 batch_id=188:  40%|████      | 188/469 [00:08<00:13, 20.97it/s]\u001b[A\n",
            "loss=1.9054688215255737 batch_id=189:  40%|████      | 188/469 [00:08<00:13, 20.97it/s]\u001b[A\n",
            "loss=1.9342552423477173 batch_id=190:  40%|████      | 188/469 [00:08<00:13, 20.97it/s]\u001b[A\n",
            "loss=1.9342552423477173 batch_id=190:  41%|████      | 191/469 [00:08<00:13, 21.03it/s]\u001b[A\n",
            "loss=2.0431125164031982 batch_id=191:  41%|████      | 191/469 [00:08<00:13, 21.03it/s]\u001b[A\n",
            "loss=1.7411025762557983 batch_id=192:  41%|████      | 191/469 [00:08<00:13, 21.03it/s]\u001b[A\n",
            "loss=2.0549473762512207 batch_id=193:  41%|████      | 191/469 [00:08<00:13, 21.03it/s]\u001b[A\n",
            "loss=2.0549473762512207 batch_id=193:  41%|████▏     | 194/469 [00:08<00:12, 21.43it/s]\u001b[A\n",
            "loss=1.7593917846679688 batch_id=194:  41%|████▏     | 194/469 [00:08<00:12, 21.43it/s]\u001b[A\n",
            "loss=1.972089171409607 batch_id=195:  41%|████▏     | 194/469 [00:08<00:12, 21.43it/s] \u001b[A\n",
            "loss=1.7763886451721191 batch_id=196:  41%|████▏     | 194/469 [00:08<00:12, 21.43it/s]\u001b[A\n",
            "loss=1.7763886451721191 batch_id=196:  42%|████▏     | 197/469 [00:08<00:12, 20.93it/s]\u001b[A\n",
            "loss=1.972184658050537 batch_id=197:  42%|████▏     | 197/469 [00:08<00:12, 20.93it/s] \u001b[A\n",
            "loss=1.8461402654647827 batch_id=198:  42%|████▏     | 197/469 [00:08<00:12, 20.93it/s]\u001b[A\n",
            "loss=1.891525149345398 batch_id=199:  42%|████▏     | 197/469 [00:08<00:12, 20.93it/s] \u001b[A\n",
            "loss=1.891525149345398 batch_id=199:  43%|████▎     | 200/469 [00:08<00:12, 21.47it/s]\u001b[A\n",
            "loss=1.9775676727294922 batch_id=200:  43%|████▎     | 200/469 [00:08<00:12, 21.47it/s]\u001b[A\n",
            "loss=1.9286197423934937 batch_id=201:  43%|████▎     | 200/469 [00:08<00:12, 21.47it/s]\u001b[A\n",
            "loss=1.7714122533798218 batch_id=202:  43%|████▎     | 200/469 [00:08<00:12, 21.47it/s]\u001b[A\n",
            "loss=1.7714122533798218 batch_id=202:  43%|████▎     | 203/469 [00:08<00:11, 22.18it/s]\u001b[A\n",
            "loss=2.0395736694335938 batch_id=203:  43%|████▎     | 203/469 [00:09<00:11, 22.18it/s]\u001b[A\n",
            "loss=1.9611212015151978 batch_id=204:  43%|████▎     | 203/469 [00:09<00:11, 22.18it/s]\u001b[A\n",
            "loss=1.896287441253662 batch_id=205:  43%|████▎     | 203/469 [00:09<00:11, 22.18it/s] \u001b[A\n",
            "loss=1.896287441253662 batch_id=205:  44%|████▍     | 206/469 [00:09<00:11, 22.95it/s]\u001b[A\n",
            "loss=2.043208360671997 batch_id=206:  44%|████▍     | 206/469 [00:09<00:11, 22.95it/s]\u001b[A\n",
            "loss=1.8765314817428589 batch_id=207:  44%|████▍     | 206/469 [00:09<00:11, 22.95it/s]\u001b[A\n",
            "loss=2.011280059814453 batch_id=208:  44%|████▍     | 206/469 [00:09<00:11, 22.95it/s] \u001b[A\n",
            "loss=2.011280059814453 batch_id=208:  45%|████▍     | 209/469 [00:09<00:11, 23.41it/s]\u001b[A\n",
            "loss=2.0472934246063232 batch_id=209:  45%|████▍     | 209/469 [00:09<00:11, 23.41it/s]\u001b[A\n",
            "loss=2.0528829097747803 batch_id=210:  45%|████▍     | 209/469 [00:09<00:11, 23.41it/s]\u001b[A\n",
            "loss=1.8877742290496826 batch_id=211:  45%|████▍     | 209/469 [00:09<00:11, 23.41it/s]\u001b[A\n",
            "loss=1.8877742290496826 batch_id=211:  45%|████▌     | 212/469 [00:09<00:10, 23.46it/s]\u001b[A\n",
            "loss=1.9528822898864746 batch_id=212:  45%|████▌     | 212/469 [00:09<00:10, 23.46it/s]\u001b[A\n",
            "loss=1.9414722919464111 batch_id=213:  45%|████▌     | 212/469 [00:09<00:10, 23.46it/s]\u001b[A\n",
            "loss=1.9478250741958618 batch_id=214:  45%|████▌     | 212/469 [00:09<00:10, 23.46it/s]\u001b[A\n",
            "loss=1.9478250741958618 batch_id=214:  46%|████▌     | 215/469 [00:09<00:10, 23.27it/s]\u001b[A\n",
            "loss=1.832688570022583 batch_id=215:  46%|████▌     | 215/469 [00:09<00:10, 23.27it/s] \u001b[A\n",
            "loss=1.9081368446350098 batch_id=216:  46%|████▌     | 215/469 [00:09<00:10, 23.27it/s]\u001b[A\n",
            "loss=1.8092145919799805 batch_id=217:  46%|████▌     | 215/469 [00:09<00:10, 23.27it/s]\u001b[A\n",
            "loss=1.8092145919799805 batch_id=217:  46%|████▋     | 218/469 [00:09<00:10, 23.31it/s]\u001b[A\n",
            "loss=2.0542750358581543 batch_id=218:  46%|████▋     | 218/469 [00:09<00:10, 23.31it/s]\u001b[A\n",
            "loss=1.9891695976257324 batch_id=219:  46%|████▋     | 218/469 [00:09<00:10, 23.31it/s]\u001b[A\n",
            "loss=1.8717153072357178 batch_id=220:  46%|████▋     | 218/469 [00:09<00:10, 23.31it/s]\u001b[A\n",
            "loss=1.8717153072357178 batch_id=220:  47%|████▋     | 221/469 [00:09<00:10, 23.24it/s]\u001b[A\n",
            "loss=1.9167075157165527 batch_id=221:  47%|████▋     | 221/469 [00:09<00:10, 23.24it/s]\u001b[A\n",
            "loss=1.8820163011550903 batch_id=222:  47%|████▋     | 221/469 [00:09<00:10, 23.24it/s]\u001b[A\n",
            "loss=1.9116586446762085 batch_id=223:  47%|████▋     | 221/469 [00:09<00:10, 23.24it/s]\u001b[A\n",
            "loss=1.9116586446762085 batch_id=223:  48%|████▊     | 224/469 [00:09<00:10, 23.36it/s]\u001b[A\n",
            "loss=1.848821759223938 batch_id=224:  48%|████▊     | 224/469 [00:09<00:10, 23.36it/s] \u001b[A\n",
            "loss=1.9212461709976196 batch_id=225:  48%|████▊     | 224/469 [00:09<00:10, 23.36it/s]\u001b[A\n",
            "loss=2.0450246334075928 batch_id=226:  48%|████▊     | 224/469 [00:09<00:10, 23.36it/s]\u001b[A\n",
            "loss=2.0450246334075928 batch_id=226:  48%|████▊     | 227/469 [00:09<00:10, 24.02it/s]\u001b[A\n",
            "loss=1.87430739402771 batch_id=227:  48%|████▊     | 227/469 [00:10<00:10, 24.02it/s]  \u001b[A\n",
            "loss=1.9207758903503418 batch_id=228:  48%|████▊     | 227/469 [00:10<00:10, 24.02it/s]\u001b[A\n",
            "loss=2.0615127086639404 batch_id=229:  48%|████▊     | 227/469 [00:10<00:10, 24.02it/s]\u001b[A\n",
            "loss=2.0615127086639404 batch_id=229:  49%|████▉     | 230/469 [00:10<00:10, 23.55it/s]\u001b[A\n",
            "loss=1.8589231967926025 batch_id=230:  49%|████▉     | 230/469 [00:10<00:10, 23.55it/s]\u001b[A\n",
            "loss=1.9515595436096191 batch_id=231:  49%|████▉     | 230/469 [00:10<00:10, 23.55it/s]\u001b[A\n",
            "loss=1.9111201763153076 batch_id=232:  49%|████▉     | 230/469 [00:10<00:10, 23.55it/s]\u001b[A\n",
            "loss=1.9111201763153076 batch_id=232:  50%|████▉     | 233/469 [00:10<00:09, 24.56it/s]\u001b[A\n",
            "loss=1.9702855348587036 batch_id=233:  50%|████▉     | 233/469 [00:10<00:09, 24.56it/s]\u001b[A\n",
            "loss=1.8192720413208008 batch_id=234:  50%|████▉     | 233/469 [00:10<00:09, 24.56it/s]\u001b[A\n",
            "loss=1.9441834688186646 batch_id=235:  50%|████▉     | 233/469 [00:10<00:09, 24.56it/s]\u001b[A\n",
            "loss=1.9441834688186646 batch_id=235:  50%|█████     | 236/469 [00:10<00:09, 23.97it/s]\u001b[A\n",
            "loss=1.9359279870986938 batch_id=236:  50%|█████     | 236/469 [00:10<00:09, 23.97it/s]\u001b[A\n",
            "loss=2.0169968605041504 batch_id=237:  50%|█████     | 236/469 [00:10<00:09, 23.97it/s]\u001b[A\n",
            "loss=1.841399073600769 batch_id=238:  50%|█████     | 236/469 [00:10<00:09, 23.97it/s] \u001b[A\n",
            "loss=1.841399073600769 batch_id=238:  51%|█████     | 239/469 [00:10<00:09, 24.10it/s]\u001b[A\n",
            "loss=1.847346544265747 batch_id=239:  51%|█████     | 239/469 [00:10<00:09, 24.10it/s]\u001b[A\n",
            "loss=1.9312304258346558 batch_id=240:  51%|█████     | 239/469 [00:10<00:09, 24.10it/s]\u001b[A\n",
            "loss=1.8673819303512573 batch_id=241:  51%|█████     | 239/469 [00:10<00:09, 24.10it/s]\u001b[A\n",
            "loss=1.8673819303512573 batch_id=241:  52%|█████▏    | 242/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.7862436771392822 batch_id=242:  52%|█████▏    | 242/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.9789788722991943 batch_id=243:  52%|█████▏    | 242/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.8575620651245117 batch_id=244:  52%|█████▏    | 242/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.8575620651245117 batch_id=244:  52%|█████▏    | 245/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.7122902870178223 batch_id=245:  52%|█████▏    | 245/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.9298995733261108 batch_id=246:  52%|█████▏    | 245/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.9423161745071411 batch_id=247:  52%|█████▏    | 245/469 [00:10<00:09, 24.66it/s]\u001b[A\n",
            "loss=1.9423161745071411 batch_id=247:  53%|█████▎    | 248/469 [00:10<00:09, 24.14it/s]\u001b[A\n",
            "loss=1.933008074760437 batch_id=248:  53%|█████▎    | 248/469 [00:10<00:09, 24.14it/s] \u001b[A\n",
            "loss=1.8298090696334839 batch_id=249:  53%|█████▎    | 248/469 [00:10<00:09, 24.14it/s]\u001b[A\n",
            "loss=1.8449002504348755 batch_id=250:  53%|█████▎    | 248/469 [00:10<00:09, 24.14it/s]\u001b[A\n",
            "loss=1.8449002504348755 batch_id=250:  54%|█████▎    | 251/469 [00:11<00:09, 23.19it/s]\u001b[A\n",
            "loss=1.8058594465255737 batch_id=251:  54%|█████▎    | 251/469 [00:11<00:09, 23.19it/s]\u001b[A\n",
            "loss=2.0075430870056152 batch_id=252:  54%|█████▎    | 251/469 [00:11<00:09, 23.19it/s]\u001b[A\n",
            "loss=1.9534878730773926 batch_id=253:  54%|█████▎    | 251/469 [00:11<00:09, 23.19it/s]\u001b[A\n",
            "loss=1.9534878730773926 batch_id=253:  54%|█████▍    | 254/469 [00:11<00:09, 22.12it/s]\u001b[A\n",
            "loss=1.869017243385315 batch_id=254:  54%|█████▍    | 254/469 [00:11<00:09, 22.12it/s] \u001b[A\n",
            "loss=1.925158143043518 batch_id=255:  54%|█████▍    | 254/469 [00:11<00:09, 22.12it/s]\u001b[A\n",
            "loss=1.8708518743515015 batch_id=256:  54%|█████▍    | 254/469 [00:11<00:09, 22.12it/s]\u001b[A\n",
            "loss=1.8708518743515015 batch_id=256:  55%|█████▍    | 257/469 [00:11<00:09, 22.51it/s]\u001b[A\n",
            "loss=1.958841323852539 batch_id=257:  55%|█████▍    | 257/469 [00:11<00:09, 22.51it/s] \u001b[A\n",
            "loss=1.9483089447021484 batch_id=258:  55%|█████▍    | 257/469 [00:11<00:09, 22.51it/s]\u001b[A\n",
            "loss=1.8006336688995361 batch_id=259:  55%|█████▍    | 257/469 [00:11<00:09, 22.51it/s]\u001b[A\n",
            "loss=1.8006336688995361 batch_id=259:  55%|█████▌    | 260/469 [00:11<00:09, 22.75it/s]\u001b[A\n",
            "loss=1.8963220119476318 batch_id=260:  55%|█████▌    | 260/469 [00:11<00:09, 22.75it/s]\u001b[A\n",
            "loss=1.9352848529815674 batch_id=261:  55%|█████▌    | 260/469 [00:11<00:09, 22.75it/s]\u001b[A\n",
            "loss=1.7531179189682007 batch_id=262:  55%|█████▌    | 260/469 [00:11<00:09, 22.75it/s]\u001b[A\n",
            "loss=1.7531179189682007 batch_id=262:  56%|█████▌    | 263/469 [00:11<00:08, 22.89it/s]\u001b[A\n",
            "loss=1.7905834913253784 batch_id=263:  56%|█████▌    | 263/469 [00:11<00:08, 22.89it/s]\u001b[A\n",
            "loss=1.8081077337265015 batch_id=264:  56%|█████▌    | 263/469 [00:11<00:08, 22.89it/s]\u001b[A\n",
            "loss=1.885178804397583 batch_id=265:  56%|█████▌    | 263/469 [00:11<00:08, 22.89it/s] \u001b[A\n",
            "loss=1.885178804397583 batch_id=265:  57%|█████▋    | 266/469 [00:11<00:08, 22.95it/s]\u001b[A\n",
            "loss=2.0118417739868164 batch_id=266:  57%|█████▋    | 266/469 [00:11<00:08, 22.95it/s]\u001b[A\n",
            "loss=1.8782875537872314 batch_id=267:  57%|█████▋    | 266/469 [00:11<00:08, 22.95it/s]\u001b[A\n",
            "loss=1.8647476434707642 batch_id=268:  57%|█████▋    | 266/469 [00:11<00:08, 22.95it/s]\u001b[A\n",
            "loss=1.8647476434707642 batch_id=268:  57%|█████▋    | 269/469 [00:11<00:08, 23.46it/s]\u001b[A\n",
            "loss=1.8333278894424438 batch_id=269:  57%|█████▋    | 269/469 [00:11<00:08, 23.46it/s]\u001b[A\n",
            "loss=1.9703165292739868 batch_id=270:  57%|█████▋    | 269/469 [00:11<00:08, 23.46it/s]\u001b[A\n",
            "loss=1.8334468603134155 batch_id=271:  57%|█████▋    | 269/469 [00:11<00:08, 23.46it/s]\u001b[A\n",
            "loss=1.8334468603134155 batch_id=271:  58%|█████▊    | 272/469 [00:11<00:08, 23.37it/s]\u001b[A\n",
            "loss=1.8824669122695923 batch_id=272:  58%|█████▊    | 272/469 [00:11<00:08, 23.37it/s]\u001b[A\n",
            "loss=1.9283231496810913 batch_id=273:  58%|█████▊    | 272/469 [00:11<00:08, 23.37it/s]\u001b[A\n",
            "loss=1.890094518661499 batch_id=274:  58%|█████▊    | 272/469 [00:12<00:08, 23.37it/s] \u001b[A\n",
            "loss=1.890094518661499 batch_id=274:  59%|█████▊    | 275/469 [00:12<00:08, 22.59it/s]\u001b[A\n",
            "loss=2.0676372051239014 batch_id=275:  59%|█████▊    | 275/469 [00:12<00:08, 22.59it/s]\u001b[A\n",
            "loss=1.8878631591796875 batch_id=276:  59%|█████▊    | 275/469 [00:12<00:08, 22.59it/s]\u001b[A\n",
            "loss=1.8771018981933594 batch_id=277:  59%|█████▊    | 275/469 [00:12<00:08, 22.59it/s]\u001b[A\n",
            "loss=1.8771018981933594 batch_id=277:  59%|█████▉    | 278/469 [00:12<00:08, 22.73it/s]\u001b[A\n",
            "loss=1.838524580001831 batch_id=278:  59%|█████▉    | 278/469 [00:12<00:08, 22.73it/s] \u001b[A\n",
            "loss=1.9129822254180908 batch_id=279:  59%|█████▉    | 278/469 [00:12<00:08, 22.73it/s]\u001b[A\n",
            "loss=1.8172308206558228 batch_id=280:  59%|█████▉    | 278/469 [00:12<00:08, 22.73it/s]\u001b[A\n",
            "loss=1.8172308206558228 batch_id=280:  60%|█████▉    | 281/469 [00:12<00:08, 23.19it/s]\u001b[A\n",
            "loss=2.049623727798462 batch_id=281:  60%|█████▉    | 281/469 [00:12<00:08, 23.19it/s] \u001b[A\n",
            "loss=1.8465248346328735 batch_id=282:  60%|█████▉    | 281/469 [00:12<00:08, 23.19it/s]\u001b[A\n",
            "loss=1.8511382341384888 batch_id=283:  60%|█████▉    | 281/469 [00:12<00:08, 23.19it/s]\u001b[A\n",
            "loss=1.8511382341384888 batch_id=283:  61%|██████    | 284/469 [00:12<00:07, 23.81it/s]\u001b[A\n",
            "loss=1.8728076219558716 batch_id=284:  61%|██████    | 284/469 [00:12<00:07, 23.81it/s]\u001b[A\n",
            "loss=1.9676792621612549 batch_id=285:  61%|██████    | 284/469 [00:12<00:07, 23.81it/s]\u001b[A\n",
            "loss=1.7533595561981201 batch_id=286:  61%|██████    | 284/469 [00:12<00:07, 23.81it/s]\u001b[A\n",
            "loss=1.7533595561981201 batch_id=286:  61%|██████    | 287/469 [00:12<00:07, 23.19it/s]\u001b[A\n",
            "loss=1.7972015142440796 batch_id=287:  61%|██████    | 287/469 [00:12<00:07, 23.19it/s]\u001b[A\n",
            "loss=2.0281851291656494 batch_id=288:  61%|██████    | 287/469 [00:12<00:07, 23.19it/s]\u001b[A\n",
            "loss=1.9099150896072388 batch_id=289:  61%|██████    | 287/469 [00:12<00:07, 23.19it/s]\u001b[A\n",
            "loss=1.9099150896072388 batch_id=289:  62%|██████▏   | 290/469 [00:12<00:07, 23.30it/s]\u001b[A\n",
            "loss=1.7950665950775146 batch_id=290:  62%|██████▏   | 290/469 [00:12<00:07, 23.30it/s]\u001b[A\n",
            "loss=1.8695435523986816 batch_id=291:  62%|██████▏   | 290/469 [00:12<00:07, 23.30it/s]\u001b[A\n",
            "loss=1.8639719486236572 batch_id=292:  62%|██████▏   | 290/469 [00:12<00:07, 23.30it/s]\u001b[A\n",
            "loss=1.8639719486236572 batch_id=292:  62%|██████▏   | 293/469 [00:12<00:07, 22.61it/s]\u001b[A\n",
            "loss=1.967591404914856 batch_id=293:  62%|██████▏   | 293/469 [00:12<00:07, 22.61it/s] \u001b[A\n",
            "loss=1.8702116012573242 batch_id=294:  62%|██████▏   | 293/469 [00:12<00:07, 22.61it/s]\u001b[A\n",
            "loss=1.8037461042404175 batch_id=295:  62%|██████▏   | 293/469 [00:12<00:07, 22.61it/s]\u001b[A\n",
            "loss=1.8037461042404175 batch_id=295:  63%|██████▎   | 296/469 [00:12<00:07, 23.33it/s]\u001b[A\n",
            "loss=1.8664346933364868 batch_id=296:  63%|██████▎   | 296/469 [00:12<00:07, 23.33it/s]\u001b[A\n",
            "loss=1.8538886308670044 batch_id=297:  63%|██████▎   | 296/469 [00:13<00:07, 23.33it/s]\u001b[A\n",
            "loss=1.9389585256576538 batch_id=298:  63%|██████▎   | 296/469 [00:13<00:07, 23.33it/s]\u001b[A\n",
            "loss=1.9389585256576538 batch_id=298:  64%|██████▍   | 299/469 [00:13<00:07, 23.03it/s]\u001b[A\n",
            "loss=1.9448894262313843 batch_id=299:  64%|██████▍   | 299/469 [00:13<00:07, 23.03it/s]\u001b[A\n",
            "loss=1.9146384000778198 batch_id=300:  64%|██████▍   | 299/469 [00:13<00:07, 23.03it/s]\u001b[A\n",
            "loss=1.768633246421814 batch_id=301:  64%|██████▍   | 299/469 [00:13<00:07, 23.03it/s] \u001b[A\n",
            "loss=1.768633246421814 batch_id=301:  64%|██████▍   | 302/469 [00:13<00:07, 23.13it/s]\u001b[A\n",
            "loss=1.8285853862762451 batch_id=302:  64%|██████▍   | 302/469 [00:13<00:07, 23.13it/s]\u001b[A\n",
            "loss=1.9179093837738037 batch_id=303:  64%|██████▍   | 302/469 [00:13<00:07, 23.13it/s]\u001b[A\n",
            "loss=2.025090217590332 batch_id=304:  64%|██████▍   | 302/469 [00:13<00:07, 23.13it/s] \u001b[A\n",
            "loss=2.025090217590332 batch_id=304:  65%|██████▌   | 305/469 [00:13<00:07, 22.96it/s]\u001b[A\n",
            "loss=1.772780179977417 batch_id=305:  65%|██████▌   | 305/469 [00:13<00:07, 22.96it/s]\u001b[A\n",
            "loss=1.8083875179290771 batch_id=306:  65%|██████▌   | 305/469 [00:13<00:07, 22.96it/s]\u001b[A\n",
            "loss=1.9292809963226318 batch_id=307:  65%|██████▌   | 305/469 [00:13<00:07, 22.96it/s]\u001b[A\n",
            "loss=1.9292809963226318 batch_id=307:  66%|██████▌   | 308/469 [00:13<00:07, 22.62it/s]\u001b[A\n",
            "loss=1.9378982782363892 batch_id=308:  66%|██████▌   | 308/469 [00:13<00:07, 22.62it/s]\u001b[A\n",
            "loss=1.9706746339797974 batch_id=309:  66%|██████▌   | 308/469 [00:13<00:07, 22.62it/s]\u001b[A\n",
            "loss=1.9024590253829956 batch_id=310:  66%|██████▌   | 308/469 [00:13<00:07, 22.62it/s]\u001b[A\n",
            "loss=1.9024590253829956 batch_id=310:  66%|██████▋   | 311/469 [00:13<00:06, 22.98it/s]\u001b[A\n",
            "loss=1.9035701751708984 batch_id=311:  66%|██████▋   | 311/469 [00:13<00:06, 22.98it/s]\u001b[A\n",
            "loss=1.795213222503662 batch_id=312:  66%|██████▋   | 311/469 [00:13<00:06, 22.98it/s] \u001b[A\n",
            "loss=1.790496587753296 batch_id=313:  66%|██████▋   | 311/469 [00:13<00:06, 22.98it/s]\u001b[A\n",
            "loss=1.790496587753296 batch_id=313:  67%|██████▋   | 314/469 [00:13<00:06, 23.44it/s]\u001b[A\n",
            "loss=1.9020500183105469 batch_id=314:  67%|██████▋   | 314/469 [00:13<00:06, 23.44it/s]\u001b[A\n",
            "loss=1.950797438621521 batch_id=315:  67%|██████▋   | 314/469 [00:13<00:06, 23.44it/s] \u001b[A\n",
            "loss=1.9745252132415771 batch_id=316:  67%|██████▋   | 314/469 [00:13<00:06, 23.44it/s]\u001b[A\n",
            "loss=1.9745252132415771 batch_id=316:  68%|██████▊   | 317/469 [00:13<00:06, 22.50it/s]\u001b[A\n",
            "loss=1.9204188585281372 batch_id=317:  68%|██████▊   | 317/469 [00:13<00:06, 22.50it/s]\u001b[A\n",
            "loss=1.919588327407837 batch_id=318:  68%|██████▊   | 317/469 [00:13<00:06, 22.50it/s] \u001b[A\n",
            "loss=1.8086705207824707 batch_id=319:  68%|██████▊   | 317/469 [00:14<00:06, 22.50it/s]\u001b[A\n",
            "loss=1.8086705207824707 batch_id=319:  68%|██████▊   | 320/469 [00:14<00:06, 21.42it/s]\u001b[A\n",
            "loss=2.0233514308929443 batch_id=320:  68%|██████▊   | 320/469 [00:14<00:06, 21.42it/s]\u001b[A\n",
            "loss=1.9597676992416382 batch_id=321:  68%|██████▊   | 320/469 [00:14<00:06, 21.42it/s]\u001b[A\n",
            "loss=1.940878987312317 batch_id=322:  68%|██████▊   | 320/469 [00:14<00:06, 21.42it/s] \u001b[A\n",
            "loss=1.940878987312317 batch_id=322:  69%|██████▉   | 323/469 [00:14<00:07, 20.64it/s]\u001b[A\n",
            "loss=1.9342865943908691 batch_id=323:  69%|██████▉   | 323/469 [00:14<00:07, 20.64it/s]\u001b[A\n",
            "loss=1.8122034072875977 batch_id=324:  69%|██████▉   | 323/469 [00:14<00:07, 20.64it/s]\u001b[A\n",
            "loss=1.839816689491272 batch_id=325:  69%|██████▉   | 323/469 [00:14<00:07, 20.64it/s] \u001b[A\n",
            "loss=1.839816689491272 batch_id=325:  70%|██████▉   | 326/469 [00:14<00:07, 20.39it/s]\u001b[A\n",
            "loss=1.9212523698806763 batch_id=326:  70%|██████▉   | 326/469 [00:14<00:07, 20.39it/s]\u001b[A\n",
            "loss=1.9083677530288696 batch_id=327:  70%|██████▉   | 326/469 [00:14<00:07, 20.39it/s]\u001b[A\n",
            "loss=1.9386687278747559 batch_id=328:  70%|██████▉   | 326/469 [00:14<00:07, 20.39it/s]\u001b[A\n",
            "loss=1.9386687278747559 batch_id=328:  70%|███████   | 329/469 [00:14<00:07, 19.77it/s]\u001b[A\n",
            "loss=1.9050241708755493 batch_id=329:  70%|███████   | 329/469 [00:14<00:07, 19.77it/s]\u001b[A\n",
            "loss=1.7279549837112427 batch_id=330:  70%|███████   | 329/469 [00:14<00:07, 19.77it/s]\u001b[A\n",
            "loss=1.7279549837112427 batch_id=330:  71%|███████   | 331/469 [00:14<00:07, 19.52it/s]\u001b[A\n",
            "loss=1.8564337491989136 batch_id=331:  71%|███████   | 331/469 [00:14<00:07, 19.52it/s]\u001b[A\n",
            "loss=1.8077250719070435 batch_id=332:  71%|███████   | 331/469 [00:14<00:07, 19.52it/s]\u001b[A\n",
            "loss=1.8077250719070435 batch_id=332:  71%|███████   | 333/469 [00:14<00:06, 19.48it/s]\u001b[A\n",
            "loss=1.934381127357483 batch_id=333:  71%|███████   | 333/469 [00:14<00:06, 19.48it/s] \u001b[A\n",
            "loss=1.8451472520828247 batch_id=334:  71%|███████   | 333/469 [00:14<00:06, 19.48it/s]\u001b[A\n",
            "loss=1.9503268003463745 batch_id=335:  71%|███████   | 333/469 [00:14<00:06, 19.48it/s]\u001b[A\n",
            "loss=1.9503268003463745 batch_id=335:  72%|███████▏  | 336/469 [00:14<00:06, 19.89it/s]\u001b[A\n",
            "loss=1.7382513284683228 batch_id=336:  72%|███████▏  | 336/469 [00:14<00:06, 19.89it/s]\u001b[A\n",
            "loss=1.8635879755020142 batch_id=337:  72%|███████▏  | 336/469 [00:14<00:06, 19.89it/s]\u001b[A\n",
            "loss=1.8354579210281372 batch_id=338:  72%|███████▏  | 336/469 [00:14<00:06, 19.89it/s]\u001b[A\n",
            "loss=1.8354579210281372 batch_id=338:  72%|███████▏  | 339/469 [00:14<00:06, 20.50it/s]\u001b[A\n",
            "loss=2.005892753601074 batch_id=339:  72%|███████▏  | 339/469 [00:15<00:06, 20.50it/s] \u001b[A\n",
            "loss=1.8483266830444336 batch_id=340:  72%|███████▏  | 339/469 [00:15<00:06, 20.50it/s]\u001b[A\n",
            "loss=1.9241191148757935 batch_id=341:  72%|███████▏  | 339/469 [00:15<00:06, 20.50it/s]\u001b[A\n",
            "loss=1.9241191148757935 batch_id=341:  73%|███████▎  | 342/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "loss=2.0348031520843506 batch_id=342:  73%|███████▎  | 342/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "loss=1.881577968597412 batch_id=343:  73%|███████▎  | 342/469 [00:15<00:06, 21.05it/s] \u001b[A\n",
            "loss=1.8747079372406006 batch_id=344:  73%|███████▎  | 342/469 [00:15<00:06, 21.05it/s]\u001b[A\n",
            "loss=1.8747079372406006 batch_id=344:  74%|███████▎  | 345/469 [00:15<00:06, 20.26it/s]\u001b[A\n",
            "loss=1.9672176837921143 batch_id=345:  74%|███████▎  | 345/469 [00:15<00:06, 20.26it/s]\u001b[A\n",
            "loss=1.9282660484313965 batch_id=346:  74%|███████▎  | 345/469 [00:15<00:06, 20.26it/s]\u001b[A\n",
            "loss=1.8684532642364502 batch_id=347:  74%|███████▎  | 345/469 [00:15<00:06, 20.26it/s]\u001b[A\n",
            "loss=1.8684532642364502 batch_id=347:  74%|███████▍  | 348/469 [00:15<00:05, 20.45it/s]\u001b[A\n",
            "loss=1.8981382846832275 batch_id=348:  74%|███████▍  | 348/469 [00:15<00:05, 20.45it/s]\u001b[A\n",
            "loss=1.8128808736801147 batch_id=349:  74%|███████▍  | 348/469 [00:15<00:05, 20.45it/s]\u001b[A\n",
            "loss=1.937851905822754 batch_id=350:  74%|███████▍  | 348/469 [00:15<00:05, 20.45it/s] \u001b[A\n",
            "loss=1.937851905822754 batch_id=350:  75%|███████▍  | 351/469 [00:15<00:05, 20.42it/s]\u001b[A\n",
            "loss=1.9762336015701294 batch_id=351:  75%|███████▍  | 351/469 [00:15<00:05, 20.42it/s]\u001b[A\n",
            "loss=1.9435524940490723 batch_id=352:  75%|███████▍  | 351/469 [00:15<00:05, 20.42it/s]\u001b[A\n",
            "loss=1.8635098934173584 batch_id=353:  75%|███████▍  | 351/469 [00:15<00:05, 20.42it/s]\u001b[A\n",
            "loss=1.8635098934173584 batch_id=353:  75%|███████▌  | 354/469 [00:15<00:05, 20.29it/s]\u001b[A\n",
            "loss=1.8640780448913574 batch_id=354:  75%|███████▌  | 354/469 [00:15<00:05, 20.29it/s]\u001b[A\n",
            "loss=1.8975120782852173 batch_id=355:  75%|███████▌  | 354/469 [00:15<00:05, 20.29it/s]\u001b[A\n",
            "loss=1.7802790403366089 batch_id=356:  75%|███████▌  | 354/469 [00:15<00:05, 20.29it/s]\u001b[A\n",
            "loss=1.7802790403366089 batch_id=356:  76%|███████▌  | 357/469 [00:15<00:05, 20.18it/s]\u001b[A\n",
            "loss=1.9676166772842407 batch_id=357:  76%|███████▌  | 357/469 [00:15<00:05, 20.18it/s]\u001b[A\n",
            "loss=1.8943567276000977 batch_id=358:  76%|███████▌  | 357/469 [00:15<00:05, 20.18it/s]\u001b[A\n",
            "loss=1.9448782205581665 batch_id=359:  76%|███████▌  | 357/469 [00:16<00:05, 20.18it/s]\u001b[A\n",
            "loss=1.9448782205581665 batch_id=359:  77%|███████▋  | 360/469 [00:16<00:05, 20.05it/s]\u001b[A\n",
            "loss=1.891943097114563 batch_id=360:  77%|███████▋  | 360/469 [00:16<00:05, 20.05it/s] \u001b[A\n",
            "loss=1.871356725692749 batch_id=361:  77%|███████▋  | 360/469 [00:16<00:05, 20.05it/s]\u001b[A\n",
            "loss=2.0054242610931396 batch_id=362:  77%|███████▋  | 360/469 [00:16<00:05, 20.05it/s]\u001b[A\n",
            "loss=2.0054242610931396 batch_id=362:  77%|███████▋  | 363/469 [00:16<00:05, 19.74it/s]\u001b[A\n",
            "loss=1.847420573234558 batch_id=363:  77%|███████▋  | 363/469 [00:16<00:05, 19.74it/s] \u001b[A\n",
            "loss=1.9541826248168945 batch_id=364:  77%|███████▋  | 363/469 [00:16<00:05, 19.74it/s]\u001b[A\n",
            "loss=1.9541826248168945 batch_id=364:  78%|███████▊  | 365/469 [00:16<00:05, 19.29it/s]\u001b[A\n",
            "loss=1.9491163492202759 batch_id=365:  78%|███████▊  | 365/469 [00:16<00:05, 19.29it/s]\u001b[A\n",
            "loss=1.8658391237258911 batch_id=366:  78%|███████▊  | 365/469 [00:16<00:05, 19.29it/s]\u001b[A\n",
            "loss=1.8658391237258911 batch_id=366:  78%|███████▊  | 367/469 [00:16<00:05, 19.10it/s]\u001b[A\n",
            "loss=1.7848087549209595 batch_id=367:  78%|███████▊  | 367/469 [00:16<00:05, 19.10it/s]\u001b[A\n",
            "loss=1.8408197164535522 batch_id=368:  78%|███████▊  | 367/469 [00:16<00:05, 19.10it/s]\u001b[A\n",
            "loss=1.8408197164535522 batch_id=368:  79%|███████▊  | 369/469 [00:16<00:05, 19.15it/s]\u001b[A\n",
            "loss=1.9986207485198975 batch_id=369:  79%|███████▊  | 369/469 [00:16<00:05, 19.15it/s]\u001b[A\n",
            "loss=1.8853524923324585 batch_id=370:  79%|███████▊  | 369/469 [00:16<00:05, 19.15it/s]\u001b[A\n",
            "loss=1.7932928800582886 batch_id=371:  79%|███████▊  | 369/469 [00:16<00:05, 19.15it/s]\u001b[A\n",
            "loss=1.7932928800582886 batch_id=371:  79%|███████▉  | 372/469 [00:16<00:04, 20.00it/s]\u001b[A\n",
            "loss=1.691225528717041 batch_id=372:  79%|███████▉  | 372/469 [00:16<00:04, 20.00it/s] \u001b[A\n",
            "loss=1.772336483001709 batch_id=373:  79%|███████▉  | 372/469 [00:16<00:04, 20.00it/s]\u001b[A\n",
            "loss=1.9915850162506104 batch_id=374:  79%|███████▉  | 372/469 [00:16<00:04, 20.00it/s]\u001b[A\n",
            "loss=1.9915850162506104 batch_id=374:  80%|███████▉  | 375/469 [00:16<00:04, 20.07it/s]\u001b[A\n",
            "loss=1.8426674604415894 batch_id=375:  80%|███████▉  | 375/469 [00:16<00:04, 20.07it/s]\u001b[A\n",
            "loss=1.919045090675354 batch_id=376:  80%|███████▉  | 375/469 [00:16<00:04, 20.07it/s] \u001b[A\n",
            "loss=1.9134007692337036 batch_id=377:  80%|███████▉  | 375/469 [00:16<00:04, 20.07it/s]\u001b[A\n",
            "loss=1.9134007692337036 batch_id=377:  81%|████████  | 378/469 [00:16<00:04, 20.58it/s]\u001b[A\n",
            "loss=1.9357703924179077 batch_id=378:  81%|████████  | 378/469 [00:16<00:04, 20.58it/s]\u001b[A\n",
            "loss=1.8011727333068848 batch_id=379:  81%|████████  | 378/469 [00:16<00:04, 20.58it/s]\u001b[A\n",
            "loss=1.865024447441101 batch_id=380:  81%|████████  | 378/469 [00:17<00:04, 20.58it/s] \u001b[A\n",
            "loss=1.865024447441101 batch_id=380:  81%|████████  | 381/469 [00:17<00:03, 22.09it/s]\u001b[A\n",
            "loss=1.8774892091751099 batch_id=381:  81%|████████  | 381/469 [00:17<00:03, 22.09it/s]\u001b[A\n",
            "loss=1.893842339515686 batch_id=382:  81%|████████  | 381/469 [00:17<00:03, 22.09it/s] \u001b[A\n",
            "loss=1.9994354248046875 batch_id=383:  81%|████████  | 381/469 [00:17<00:03, 22.09it/s]\u001b[A\n",
            "loss=1.9994354248046875 batch_id=383:  82%|████████▏ | 384/469 [00:17<00:03, 22.49it/s]\u001b[A\n",
            "loss=1.8969851732254028 batch_id=384:  82%|████████▏ | 384/469 [00:17<00:03, 22.49it/s]\u001b[A\n",
            "loss=1.830006718635559 batch_id=385:  82%|████████▏ | 384/469 [00:17<00:03, 22.49it/s] \u001b[A\n",
            "loss=1.9077986478805542 batch_id=386:  82%|████████▏ | 384/469 [00:17<00:03, 22.49it/s]\u001b[A\n",
            "loss=1.9077986478805542 batch_id=386:  83%|████████▎ | 387/469 [00:17<00:03, 21.60it/s]\u001b[A\n",
            "loss=1.8101252317428589 batch_id=387:  83%|████████▎ | 387/469 [00:17<00:03, 21.60it/s]\u001b[A\n",
            "loss=1.8648110628128052 batch_id=388:  83%|████████▎ | 387/469 [00:17<00:03, 21.60it/s]\u001b[A\n",
            "loss=1.991939663887024 batch_id=389:  83%|████████▎ | 387/469 [00:17<00:03, 21.60it/s] \u001b[A\n",
            "loss=1.991939663887024 batch_id=389:  83%|████████▎ | 390/469 [00:17<00:03, 22.23it/s]\u001b[A\n",
            "loss=1.9576970338821411 batch_id=390:  83%|████████▎ | 390/469 [00:17<00:03, 22.23it/s]\u001b[A\n",
            "loss=1.8664883375167847 batch_id=391:  83%|████████▎ | 390/469 [00:17<00:03, 22.23it/s]\u001b[A\n",
            "loss=1.795357584953308 batch_id=392:  83%|████████▎ | 390/469 [00:17<00:03, 22.23it/s] \u001b[A\n",
            "loss=1.795357584953308 batch_id=392:  84%|████████▍ | 393/469 [00:17<00:03, 22.42it/s]\u001b[A\n",
            "loss=1.9276264905929565 batch_id=393:  84%|████████▍ | 393/469 [00:17<00:03, 22.42it/s]\u001b[A\n",
            "loss=1.8983181715011597 batch_id=394:  84%|████████▍ | 393/469 [00:17<00:03, 22.42it/s]\u001b[A\n",
            "loss=1.8684821128845215 batch_id=395:  84%|████████▍ | 393/469 [00:17<00:03, 22.42it/s]\u001b[A\n",
            "loss=1.8684821128845215 batch_id=395:  84%|████████▍ | 396/469 [00:17<00:03, 21.80it/s]\u001b[A\n",
            "loss=1.8243461847305298 batch_id=396:  84%|████████▍ | 396/469 [00:17<00:03, 21.80it/s]\u001b[A\n",
            "loss=1.8841074705123901 batch_id=397:  84%|████████▍ | 396/469 [00:17<00:03, 21.80it/s]\u001b[A\n",
            "loss=1.9126019477844238 batch_id=398:  84%|████████▍ | 396/469 [00:17<00:03, 21.80it/s]\u001b[A\n",
            "loss=1.9126019477844238 batch_id=398:  85%|████████▌ | 399/469 [00:17<00:03, 20.98it/s]\u001b[A\n",
            "loss=1.8984166383743286 batch_id=399:  85%|████████▌ | 399/469 [00:17<00:03, 20.98it/s]\u001b[A\n",
            "loss=1.955021858215332 batch_id=400:  85%|████████▌ | 399/469 [00:17<00:03, 20.98it/s] \u001b[A\n",
            "loss=1.984433650970459 batch_id=401:  85%|████████▌ | 399/469 [00:18<00:03, 20.98it/s]\u001b[A\n",
            "loss=1.984433650970459 batch_id=401:  86%|████████▌ | 402/469 [00:18<00:03, 21.49it/s]\u001b[A\n",
            "loss=1.8181326389312744 batch_id=402:  86%|████████▌ | 402/469 [00:18<00:03, 21.49it/s]\u001b[A\n",
            "loss=1.9192231893539429 batch_id=403:  86%|████████▌ | 402/469 [00:18<00:03, 21.49it/s]\u001b[A\n",
            "loss=1.9189907312393188 batch_id=404:  86%|████████▌ | 402/469 [00:18<00:03, 21.49it/s]\u001b[A\n",
            "loss=1.9189907312393188 batch_id=404:  86%|████████▋ | 405/469 [00:18<00:02, 21.68it/s]\u001b[A\n",
            "loss=1.8406577110290527 batch_id=405:  86%|████████▋ | 405/469 [00:18<00:02, 21.68it/s]\u001b[A\n",
            "loss=1.8864158391952515 batch_id=406:  86%|████████▋ | 405/469 [00:18<00:02, 21.68it/s]\u001b[A\n",
            "loss=1.7303078174591064 batch_id=407:  86%|████████▋ | 405/469 [00:18<00:02, 21.68it/s]\u001b[A\n",
            "loss=1.7303078174591064 batch_id=407:  87%|████████▋ | 408/469 [00:18<00:02, 21.42it/s]\u001b[A\n",
            "loss=1.8293391466140747 batch_id=408:  87%|████████▋ | 408/469 [00:18<00:02, 21.42it/s]\u001b[A\n",
            "loss=1.8497868776321411 batch_id=409:  87%|████████▋ | 408/469 [00:18<00:02, 21.42it/s]\u001b[A\n",
            "loss=1.898270845413208 batch_id=410:  87%|████████▋ | 408/469 [00:18<00:02, 21.42it/s] \u001b[A\n",
            "loss=1.898270845413208 batch_id=410:  88%|████████▊ | 411/469 [00:18<00:02, 22.51it/s]\u001b[A\n",
            "loss=1.765605092048645 batch_id=411:  88%|████████▊ | 411/469 [00:18<00:02, 22.51it/s]\u001b[A\n",
            "loss=1.8940025568008423 batch_id=412:  88%|████████▊ | 411/469 [00:18<00:02, 22.51it/s]\u001b[A\n",
            "loss=1.9451760053634644 batch_id=413:  88%|████████▊ | 411/469 [00:18<00:02, 22.51it/s]\u001b[A\n",
            "loss=1.9451760053634644 batch_id=413:  88%|████████▊ | 414/469 [00:18<00:02, 22.96it/s]\u001b[A\n",
            "loss=2.0294992923736572 batch_id=414:  88%|████████▊ | 414/469 [00:18<00:02, 22.96it/s]\u001b[A\n",
            "loss=1.786026120185852 batch_id=415:  88%|████████▊ | 414/469 [00:18<00:02, 22.96it/s] \u001b[A\n",
            "loss=1.804566740989685 batch_id=416:  88%|████████▊ | 414/469 [00:18<00:02, 22.96it/s]\u001b[A\n",
            "loss=1.804566740989685 batch_id=416:  89%|████████▉ | 417/469 [00:18<00:02, 22.76it/s]\u001b[A\n",
            "loss=1.8725706338882446 batch_id=417:  89%|████████▉ | 417/469 [00:18<00:02, 22.76it/s]\u001b[A\n",
            "loss=1.9167336225509644 batch_id=418:  89%|████████▉ | 417/469 [00:18<00:02, 22.76it/s]\u001b[A\n",
            "loss=1.9208440780639648 batch_id=419:  89%|████████▉ | 417/469 [00:18<00:02, 22.76it/s]\u001b[A\n",
            "loss=1.9208440780639648 batch_id=419:  90%|████████▉ | 420/469 [00:18<00:02, 23.16it/s]\u001b[A\n",
            "loss=1.880393624305725 batch_id=420:  90%|████████▉ | 420/469 [00:18<00:02, 23.16it/s] \u001b[A\n",
            "loss=1.9890581369400024 batch_id=421:  90%|████████▉ | 420/469 [00:18<00:02, 23.16it/s]\u001b[A\n",
            "loss=1.9517546892166138 batch_id=422:  90%|████████▉ | 420/469 [00:18<00:02, 23.16it/s]\u001b[A\n",
            "loss=1.9517546892166138 batch_id=422:  90%|█████████ | 423/469 [00:18<00:01, 23.11it/s]\u001b[A\n",
            "loss=1.9161484241485596 batch_id=423:  90%|█████████ | 423/469 [00:18<00:01, 23.11it/s]\u001b[A\n",
            "loss=1.8158329725265503 batch_id=424:  90%|█████████ | 423/469 [00:19<00:01, 23.11it/s]\u001b[A\n",
            "loss=1.8312466144561768 batch_id=425:  90%|█████████ | 423/469 [00:19<00:01, 23.11it/s]\u001b[A\n",
            "loss=1.8312466144561768 batch_id=425:  91%|█████████ | 426/469 [00:19<00:01, 22.62it/s]\u001b[A\n",
            "loss=1.921707272529602 batch_id=426:  91%|█████████ | 426/469 [00:19<00:01, 22.62it/s] \u001b[A\n",
            "loss=1.9258742332458496 batch_id=427:  91%|█████████ | 426/469 [00:19<00:01, 22.62it/s]\u001b[A\n",
            "loss=1.8595613241195679 batch_id=428:  91%|█████████ | 426/469 [00:19<00:01, 22.62it/s]\u001b[A\n",
            "loss=1.8595613241195679 batch_id=428:  91%|█████████▏| 429/469 [00:19<00:01, 22.41it/s]\u001b[A\n",
            "loss=1.8718883991241455 batch_id=429:  91%|█████████▏| 429/469 [00:19<00:01, 22.41it/s]\u001b[A\n",
            "loss=1.8195587396621704 batch_id=430:  91%|█████████▏| 429/469 [00:19<00:01, 22.41it/s]\u001b[A\n",
            "loss=1.8507038354873657 batch_id=431:  91%|█████████▏| 429/469 [00:19<00:01, 22.41it/s]\u001b[A\n",
            "loss=1.8507038354873657 batch_id=431:  92%|█████████▏| 432/469 [00:19<00:01, 22.79it/s]\u001b[A\n",
            "loss=1.7802975177764893 batch_id=432:  92%|█████████▏| 432/469 [00:19<00:01, 22.79it/s]\u001b[A\n",
            "loss=1.8167121410369873 batch_id=433:  92%|█████████▏| 432/469 [00:19<00:01, 22.79it/s]\u001b[A\n",
            "loss=1.77850341796875 batch_id=434:  92%|█████████▏| 432/469 [00:19<00:01, 22.79it/s]  \u001b[A\n",
            "loss=1.77850341796875 batch_id=434:  93%|█████████▎| 435/469 [00:19<00:01, 22.23it/s]\u001b[A\n",
            "loss=1.9934000968933105 batch_id=435:  93%|█████████▎| 435/469 [00:19<00:01, 22.23it/s]\u001b[A\n",
            "loss=1.8950968980789185 batch_id=436:  93%|█████████▎| 435/469 [00:19<00:01, 22.23it/s]\u001b[A\n",
            "loss=1.8417176008224487 batch_id=437:  93%|█████████▎| 435/469 [00:19<00:01, 22.23it/s]\u001b[A\n",
            "loss=1.8417176008224487 batch_id=437:  93%|█████████▎| 438/469 [00:19<00:01, 23.03it/s]\u001b[A\n",
            "loss=1.8374441862106323 batch_id=438:  93%|█████████▎| 438/469 [00:19<00:01, 23.03it/s]\u001b[A\n",
            "loss=1.9554686546325684 batch_id=439:  93%|█████████▎| 438/469 [00:19<00:01, 23.03it/s]\u001b[A\n",
            "loss=1.8275395631790161 batch_id=440:  93%|█████████▎| 438/469 [00:19<00:01, 23.03it/s]\u001b[A\n",
            "loss=1.8275395631790161 batch_id=440:  94%|█████████▍| 441/469 [00:19<00:01, 21.88it/s]\u001b[A\n",
            "loss=1.7078567743301392 batch_id=441:  94%|█████████▍| 441/469 [00:19<00:01, 21.88it/s]\u001b[A\n",
            "loss=1.8992445468902588 batch_id=442:  94%|█████████▍| 441/469 [00:19<00:01, 21.88it/s]\u001b[A\n",
            "loss=1.9526771306991577 batch_id=443:  94%|█████████▍| 441/469 [00:19<00:01, 21.88it/s]\u001b[A\n",
            "loss=1.9526771306991577 batch_id=443:  95%|█████████▍| 444/469 [00:19<00:01, 21.44it/s]\u001b[A\n",
            "loss=1.907024621963501 batch_id=444:  95%|█████████▍| 444/469 [00:19<00:01, 21.44it/s] \u001b[A\n",
            "loss=1.9702774286270142 batch_id=445:  95%|█████████▍| 444/469 [00:19<00:01, 21.44it/s]\u001b[A\n",
            "loss=2.002514600753784 batch_id=446:  95%|█████████▍| 444/469 [00:20<00:01, 21.44it/s] \u001b[A\n",
            "loss=2.002514600753784 batch_id=446:  95%|█████████▌| 447/469 [00:20<00:01, 21.75it/s]\u001b[A\n",
            "loss=1.9786977767944336 batch_id=447:  95%|█████████▌| 447/469 [00:20<00:01, 21.75it/s]\u001b[A\n",
            "loss=1.858730673789978 batch_id=448:  95%|█████████▌| 447/469 [00:20<00:01, 21.75it/s] \u001b[A\n",
            "loss=2.012460231781006 batch_id=449:  95%|█████████▌| 447/469 [00:20<00:01, 21.75it/s]\u001b[A\n",
            "loss=2.012460231781006 batch_id=449:  96%|█████████▌| 450/469 [00:20<00:00, 21.82it/s]\u001b[A\n",
            "loss=1.8810664415359497 batch_id=450:  96%|█████████▌| 450/469 [00:20<00:00, 21.82it/s]\u001b[A\n",
            "loss=1.8930367231369019 batch_id=451:  96%|█████████▌| 450/469 [00:20<00:00, 21.82it/s]\u001b[A\n",
            "loss=1.903747320175171 batch_id=452:  96%|█████████▌| 450/469 [00:20<00:00, 21.82it/s] \u001b[A\n",
            "loss=1.903747320175171 batch_id=452:  97%|█████████▋| 453/469 [00:20<00:00, 21.23it/s]\u001b[A\n",
            "loss=1.8393065929412842 batch_id=453:  97%|█████████▋| 453/469 [00:20<00:00, 21.23it/s]\u001b[A\n",
            "loss=1.8847497701644897 batch_id=454:  97%|█████████▋| 453/469 [00:20<00:00, 21.23it/s]\u001b[A\n",
            "loss=1.827771544456482 batch_id=455:  97%|█████████▋| 453/469 [00:20<00:00, 21.23it/s] \u001b[A\n",
            "loss=1.827771544456482 batch_id=455:  97%|█████████▋| 456/469 [00:20<00:00, 22.47it/s]\u001b[A\n",
            "loss=1.9307533502578735 batch_id=456:  97%|█████████▋| 456/469 [00:20<00:00, 22.47it/s]\u001b[A\n",
            "loss=1.7335759401321411 batch_id=457:  97%|█████████▋| 456/469 [00:20<00:00, 22.47it/s]\u001b[A\n",
            "loss=1.9355584383010864 batch_id=458:  97%|█████████▋| 456/469 [00:20<00:00, 22.47it/s]\u001b[A\n",
            "loss=1.9355584383010864 batch_id=458:  98%|█████████▊| 459/469 [00:20<00:00, 22.17it/s]\u001b[A\n",
            "loss=1.9466848373413086 batch_id=459:  98%|█████████▊| 459/469 [00:20<00:00, 22.17it/s]\u001b[A\n",
            "loss=1.839387059211731 batch_id=460:  98%|█████████▊| 459/469 [00:20<00:00, 22.17it/s] \u001b[A\n",
            "loss=1.9739916324615479 batch_id=461:  98%|█████████▊| 459/469 [00:20<00:00, 22.17it/s]\u001b[A\n",
            "loss=1.9739916324615479 batch_id=461:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "loss=1.9353069067001343 batch_id=462:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "loss=1.8295823335647583 batch_id=463:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "loss=1.8936961889266968 batch_id=464:  99%|█████████▊| 462/469 [00:20<00:00, 22.30it/s]\u001b[A\n",
            "loss=1.8936961889266968 batch_id=464:  99%|█████████▉| 465/469 [00:20<00:00, 21.64it/s]\u001b[A\n",
            "loss=1.9725838899612427 batch_id=465:  99%|█████████▉| 465/469 [00:20<00:00, 21.64it/s]\u001b[A\n",
            "loss=1.8710843324661255 batch_id=466:  99%|█████████▉| 465/469 [00:20<00:00, 21.64it/s]\u001b[A\n",
            "loss=1.8413280248641968 batch_id=467:  99%|█████████▉| 465/469 [00:20<00:00, 21.64it/s]\u001b[A\n",
            "loss=1.8413280248641968 batch_id=467: 100%|█████████▉| 468/469 [00:20<00:00, 22.23it/s]\u001b[A\n",
            "loss=1.9772820472717285 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.8797, Accuracy: 2927/10000 (29%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}